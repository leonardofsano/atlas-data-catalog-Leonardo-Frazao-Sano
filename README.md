# Apache Atlas DataOps Lab

> **Laborat√≥rio completo para aprendizado de cataloga√ß√£o de dados com Apache Atlas, PostgreSQL e Python**

## Sobre o Projeto

Este reposit√≥rio fornece um ambiente completo de aprendizado para **Data Governance** e **DataOps** usando Apache Atlas como cat√°logo de dados. O projeto demonstra desde conceitos b√°sicos at√© implementa√ß√µes avan√ßadas de descoberta autom√°tica de metadados, linhagem de dados e integra√ß√£o com bancos relacionais.

### Objetivos de Aprendizado

- **Cataloga√ß√£o de Dados**: Criar e gerenciar cat√°logos de metadados
- **API Integration**: Integrar sistemas via REST APIs do Apache Atlas
- **Data Lineage**: Mapear origem e transforma√ß√µes de dados
- **Metadata Management**: Extrair e organizar metadados estruturais
- **DataOps Practices**: Automatizar descoberta e cataloga√ß√£o

## Arquitetura do Sistema

### Stack Tecnol√≥gica

| Componente | Tecnologia | Vers√£o | Porta | Fun√ß√£o |
|------------|------------|--------|-------|--------|
| **Cat√°logo** | Apache Atlas | 2.3.0 | 21000 | Governan√ßa e metadados |
| **Database** | PostgreSQL | 14.19 | 2001 | Dados de exemplo (Northwind) |
| **Analytics** | PySpark + Jupyter | Latest | 8888 | An√°lise e notebooks |
| **Storage** | HBase (embedded) | - | - | Persist√™ncia Atlas |
| **Search** | Apache Solr (embedded) | - | - | Indexa√ß√£o e busca |
| **Messaging** | Apache Kafka (embedded) | - | - | Eventos e notifica√ß√µes |

## Estrutura do Reposit√≥rio

```
atlas-dataops-lab/
‚îú‚îÄ‚îÄ docker-compose.yml          # Orquestra√ß√£o dos servi√ßos
‚îú‚îÄ‚îÄ Dockerfile                  # Atlas customizado
‚îú‚îÄ‚îÄ Dockerfile_Spark           # PySpark + Jupyter
‚îú‚îÄ‚îÄ wait-for-atlas.sh          # Script de inicializa√ß√£o
‚îú‚îÄ‚îÄ users-credentials.properties # Autentica√ß√£o Atlas
‚îú‚îÄ‚îÄ LICENSE                    # Licen√ßa do projeto
‚îú‚îÄ‚îÄ README.md                  # Este arquivo
‚îú‚îÄ‚îÄ .gitignore                # Arquivos ignorados
‚îÇ
‚îú‚îÄ‚îÄ data/                      # Datasets para an√°lise
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îî‚îÄ‚îÄ northwind.sql          # Schema e dados PostgreSQL
‚îÇ
‚îú‚îÄ‚îÄ Exercicios/
‚îÇ   ‚îî‚îÄ‚îÄ EXERCICIO_ATLAS.md     # Exerc√≠cio pr√°tico completo
‚îÇ
‚îú‚îÄ‚îÄ lab/
‚îÇ   ‚îú‚îÄ‚îÄ atlas_client.py        # Cliente Python para Atlas API
‚îÇ   ‚îú‚îÄ‚îÄ config.py              # Configura√ß√µes do laborat√≥rio
‚îÇ   ‚îú‚îÄ‚îÄ data_discovery.py      # Descoberta de dados
‚îÇ   ‚îú‚îÄ‚îÄ lineage_demo.py        # Demonstra√ß√£o de linhagem
‚îÇ   ‚îú‚îÄ‚îÄ postgres_integration.py # Integra√ß√£o PostgreSQL
‚îÇ   ‚îú‚îÄ‚îÄ LAB_ATLAS_PYTHON.md    # Guia do laborat√≥rio Python
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îÇ   ‚îî‚îÄ‚îÄ run_lab.sh            # Script de execu√ß√£o
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ Lab_Catalogo_Postgres_no_Atlas.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ data/                  # Dados para notebooks
‚îÇ
‚îî‚îÄ‚îÄ respostas/
    ‚îú‚îÄ‚îÄ config_exercicio.py    # Configura√ß√µes do exerc√≠cio
    ‚îú‚îÄ‚îÄ requirements_exercicio.txt # Depend√™ncias do exerc√≠cio
    ‚îî‚îÄ‚îÄ SOLUCAO_EXERCICIO.py   # Solu√ß√£o completa
```

## In√≠cio R√°pido

### 1. Pr√©-requisitos

- **Docker** >= 20.10
- **Docker Compose** >= 2.0
- **Python** >= 3.8 (opcional, para desenvolvimento local)
- **8GB RAM** dispon√≠vel (recomendado)

### 2. Inicializa√ß√£o

```bash
# Clonar o reposit√≥rio
git clone <URL_DO_REPOSITORIO>
cd atlas-dataops-lab

# Iniciar todos os servi√ßos
docker-compose up --build -d

# Aguardar inicializa√ß√£o (5-10 minutos)
./wait-for-atlas.sh

# Verificar status dos servi√ßos
docker-compose ps
```

### 3. Acesso aos Servi√ßos

| Servi√ßo | URL | Credenciais |
|---------|-----|-------------|
| **Apache Atlas** | http://localhost:21000 | admin / admin |
| **Jupyter Notebook** | http://localhost:8888 | Token: tavares1234 |
| **PostgreSQL** | localhost:2001 | postgres / postgres |

## Laborat√≥rios Dispon√≠veis

### Lab 1: Cliente Atlas B√°sico
```bash
cd lab
pip install -r requirements.txt
python atlas_client.py
```
**Aprenda**: Conex√£o com Atlas, busca de entidades, API REST

### Lab 2: Jupyter Notebook Interativo
```bash
# Acessar: http://localhost:8888 (token: tavares1234)
# Abrir: Lab_Catalogo_Postgres_no_Atlas.ipynb
```
**Aprenda**: Extra√ß√£o de metadados, cataloga√ß√£o autom√°tica, visualiza√ß√£o

### Lab 3: Exerc√≠cio Pr√°tico Completo
```bash
# Seguir instru√ß√µes em EXERCICIO_ATLAS.md
```
**Aprenda**: Implementa√ß√£o completa de catalogador de dados

## Configura√ß√µes Detalhadas

### Apache Atlas
- **Modo**: Standalone com componentes embedded
- **Storage**: BerkeleyDB para grafos, HBase para metadados
- **Search**: Apache Solr embedded
- **Messaging**: Kafka embedded para eventos
- **Autentica√ß√£o**: File-based (users-credentials.properties)
- **Mem√≥ria**: 1GB heap, 512MB inicial
- **Persist√™ncia**: Volume Docker `atlas_data`

### PostgreSQL Northwind
- **Database**: northwind (carregado automaticamente)
- **Tabelas**: 14 tabelas relacionais completas
  - `customers`, `products`, `orders`, `order_details`
  - `employees`, `categories`, `suppliers`, `shippers`
  - `territories`, `region`, `employee_territories`
  - `customer_demographics`, `customer_customer_demo`
- **Dados**: ~3000 registros com relacionamentos
- **Persist√™ncia**: Volume Docker `postgres_data`

### PySpark + Jupyter
- **Base Image**: jupyter/pyspark-notebook:latest
- **Packages**: requests, psycopg2-binary, pandas, matplotlib, seaborn
- **Volumes**: notebooks/ e data/ mapeados
- **Spark UI**: http://localhost:4040 (quando jobs est√£o rodando)

## Comandos √öteis

### Gerenciamento de Servi√ßos
```bash
# Ver logs espec√≠ficos
docker-compose logs -f atlas
docker-compose logs -f postgres_erp
docker-compose logs -f pyspark-aula

# Reiniciar servi√ßo espec√≠fico
docker-compose restart atlas

# Parar todos os servi√ßos
docker-compose down

# Limpar volumes (CUIDADO: perde dados)
docker-compose down -v

# Rebuild completo
docker-compose up --build --force-recreate
```

### Diagn√≥stico
```bash
# Testar conectividade Atlas
curl -u admin:admin http://localhost:21000/api/atlas/admin/version

# Testar PostgreSQL
docker exec -it postgres-erp psql -U postgres -d northwind -c "SELECT count(*) FROM customers;"

# Verificar recursos
docker stats
```

## Casos de Uso Educacionais

### 1. **Data Discovery**
- Descoberta autom√°tica de esquemas de banco
- Cataloga√ß√£o de tabelas e colunas
- Busca e navega√ß√£o no cat√°logo

### 2. **Metadata Management**
- Extra√ß√£o de metadados estruturais
- Cria√ß√£o de entidades no Atlas
- Relacionamentos entre entidades

### 3. **Data Lineage**
- Mapeamento de origem dos dados
- Rastreamento de transforma√ß√µes
- Visualiza√ß√£o de fluxos de dados

### 4. **API Integration**
- Uso de REST APIs do Atlas
- Autentica√ß√£o e autoriza√ß√£o
- Opera√ß√µes CRUD em metadados

### 5. **DataOps Automation**
- Scripts de cataloga√ß√£o autom√°tica
- Integra√ß√£o com pipelines CI/CD
- Monitoramento de qualidade de dados

## Pr√≥ximos Passos - Roadmap

### Evolu√ß√£o para Plataforma DataOps Completa

Os pr√≥ximos desenvolvimentos deste reposit√≥rio incluir√£o a implementa√ß√£o de uma **plataforma DataOps completa** com orquestra√ß√£o avan√ßada e linhagem autom√°tica de dados:

#### **Apache Airflow - Orquestra√ß√£o de ETLs**
- **Scheduler Avan√ßado**: Orquestra√ß√£o de pipelines de dados complexos
- **DAGs Automatizados**: Workflows para descoberta e cataloga√ß√£o cont√≠nua
- **Monitoramento**: Interface web para acompanhamento de execu√ß√µes
- **Integra√ß√£o Atlas**: DAGs espec√≠ficos para sincroniza√ß√£o de metadados

#### **Apache Spark - Engine de Transforma√ß√£o**
- **Processamento Distribu√≠do**: Transforma√ß√µes em larga escala
- **Conectores Nativos**: Integra√ß√£o direta com PostgreSQL e Atlas
- **Spark Streaming**: Processamento de dados em tempo real
- **Delta Lake**: Versionamento e qualidade de dados

#### **Linhagem Autom√°tica de Dados**
- **Rastreamento Completo**: Origem ‚Üí Transforma√ß√£o ‚Üí Destino
- **Spark Lineage**: Captura autom√°tica via Spark Listener
- **Atlas Integration**: Registro autom√°tico de processos ETL
- **Visualiza√ß√£o Gr√°fica**: Mapeamento visual de fluxos de dados

### **Arquitetura Futura**

### **Funcionalidades Planejadas**

| Componente | Funcionalidade | Status |
|------------|----------------|--------|
| **Airflow** | DAGs de cataloga√ß√£o autom√°tica | Em desenvolvimento |
| **Spark** | Jobs ETL com linhagem | Em desenvolvimento |
| **Atlas** | Linhagem autom√°tica de processos | Em desenvolvimento |
| **Monitoring** | Dashboard de qualidade de dados | Planejado |
| **Governance** | Pol√≠ticas automatizadas | Planejado |

### **Benef√≠cios da Evolu√ß√£o**

- **Automa√ß√£o Completa**: Descoberta e cataloga√ß√£o sem interven√ß√£o manual
- **Linhagem End-to-End**: Rastreamento completo do ciclo de vida dos dados
- **Escalabilidade**: Processamento distribu√≠do para grandes volumes
- **Governan√ßa Avan√ßada**: Pol√≠ticas e qualidade automatizadas
- **Observabilidade**: Monitoramento completo de pipelines

### **Como Contribuir**

Interessado em contribuir com essas funcionalidades? √Åreas de desenvolvimento:

- **Airflow DAGs**: Desenvolvimento de workflows de cataloga√ß√£o
- **Spark Jobs**: Implementa√ß√£o de ETLs com captura de linhagem
- **Atlas Hooks**: Conectores customizados para diferentes fontes
- **Monitoring**: Dashboards e alertas de qualidade
- **Documentation**: Tutoriais e guias avan√ßados

## Contribui√ß√£o

Este √© um projeto educacional. Contribui√ß√µes s√£o bem-vindas:

1. **Fork** o reposit√≥rio
2. **Crie** uma branch para sua feature
3. **Commit** suas mudan√ßas
4. **Push** para a branch
5. **Abra** um Pull Request

### √Åreas de Melhoria Atuais
- Novos conectores de dados
- Exemplos de classifica√ß√£o autom√°tica
- Integra√ß√£o com ferramentas de BI
- Testes automatizados
- Documenta√ß√£o adicional

## Licen√ßa

Este projeto est√° sob a licen√ßa MIT. Veja o arquivo [LICENSE](LICENSE) para detalhes.

## Agradecimentos

- **Apache Atlas Community** - Pela excelente ferramenta de governan√ßa
- **Northwind Database** - Pelo dataset educacional cl√°ssico
- **Docker Community** - Pela containeriza√ß√£o simplificada
- **Jupyter Project** - Pelo ambiente interativo de an√°lise

**üìö Para come√ßar, acesse os laborat√≥rios em ordem:**
1. [Lab Python B√°sico](lab/LAB_ATLAS_PYTHON.md)
2. [Exerc√≠cio Pr√°tico](Exercicios/EXERCICIO_ATLAS.md)
3. [Notebook Interativo](notebooks/Lab_Catalogo_Postgres_no_Atlas.ipynb)